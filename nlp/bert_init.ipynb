{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert_init.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZX8fcX6Gp__"
      },
      "source": [
        "import re\n",
        "import math\n",
        "import torch\n",
        "import numpy as np\n",
        "from random import *\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as Data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUQe-UuCHMJ_"
      },
      "source": [
        "text = (\n",
        "    'Hello, how are you? I am Romeo.\\n' # R\n",
        "    'Hello, Romeo My name is Juliet. Nice to meet you.\\n' # J\n",
        "    'Nice meet you too. How are you today?\\n' # R\n",
        "    'Great. My baseball team won the competition.\\n' # J\n",
        "    'Oh Congratulations, Juliet\\n' # R\n",
        "    'Thank you Romeo\\n' # J\n",
        "    'Where are you going today?\\n' # R\n",
        "    'I am going shopping. What about you?\\n' # J\n",
        "    'I am going to visit my grandmother. she is not very well' # R\n",
        ")\n",
        "sentences = re.sub(\"[.,!?\\\\-]\", '', text.lower()).split('\\n')\n",
        "word_list = list(set(\" \".join(sentences).split())) \n",
        "word2idx = {'[PAD]' : 0, '[CLS]' : 1, '[SEP]' : 2, '[MASK]' : 3}\n",
        "for i, w in enumerate(word_list):\n",
        "    word2idx[w] = i + 4\n",
        "idx2word = {i: w for i, w in enumerate(word2idx)}\n",
        "vocab_size = len(word2idx)\n",
        "\n",
        "token_list = []\n",
        "for sentence in sentences:\n",
        "    arr = [word2idx[s] for s in sentence.split()]\n",
        "    token_list.append(arr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55rYk1D4JupW"
      },
      "source": [
        "maxlen = 30\n",
        "batch_size = 6\n",
        "max_pred = 5 \n",
        "n_layers = 6\n",
        "n_heads = 12\n",
        "d_model = 768\n",
        "d_ff = 768*4 \n",
        "d_k = d_v = 64  \n",
        "n_segments = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w61AxCtyJ9Q4"
      },
      "source": [
        "def make_data():\n",
        "  batch = []\n",
        "  positive_candis = np.random\n",
        "  for idx in range(batch_size):\n",
        "    # 正样本，连续两个句子拼接\n",
        "    if idx%2 == 0:\n",
        "      aid = randrange(len(sentences) - 1)\n",
        "      bid = aid + 1\n",
        "    # 负样本，随机两个句子拼接\n",
        "    else:\n",
        "      aid, bid = randrange(len(sentences)), randrange(len(sentences))\n",
        "    tokena, tokenb = token_list[aid], token_list[bid]\n",
        "    input_ids = [word2idx['[CLS]']] + tokena + [word2idx['[SEP]']] + tokenb + [word2idx['[SEP]']]\n",
        "    segment_ids = [0] * (len(tokena) + 2) + [1] * (len(tokenb) + 1)\n",
        "\n",
        "    # 特殊处理15%的单词\n",
        "    n_pred = min(max_pred, max(1, int(len(input_ids) * 0.15)))\n",
        "    masked_candis = [i for i, t in enumerate(input_ids) if idx2word[t] not in ['[CLS]', '[SEP]']]\n",
        "    shuffle(masked_candis)\n",
        "    masked_pos = masked_candis[: n_pred]\n",
        "    masked_tokens = [input_ids[i] for i in masked_pos]\n",
        "    # print(masked_candis)\n",
        "    # print(masked_pos, masked_tokens)\n",
        "    for i in masked_pos:\n",
        "      r = random()\n",
        "      if r < 0.8:\n",
        "        input_ids[i] = word2idx['[MASK]']\n",
        "      elif r > 0.9:\n",
        "        # 随机选取一个单词替换，注意不能用标识符替换\n",
        "        ri = randrange(4, vocab_size - 1)\n",
        "        input_ids[i] = ri\n",
        "    # 0 paddding。分为对整个样本的padding以及遮挡部分未满max_pred的padding\n",
        "    n1 = maxlen - len(input_ids)\n",
        "    input_ids += [0] * n1\n",
        "    segment_ids += [0] * n1\n",
        "\n",
        "    n2 = max_pred - n_pred\n",
        "    masked_tokens += [word2idx['[PAD]']] * n2\n",
        "    masked_pos += [0] * n2\n",
        "    if idx%2 == 0:\n",
        "      batch.append([input_ids, segment_ids, masked_tokens, masked_pos, True])\n",
        "    else:\n",
        "      batch.append([input_ids, segment_ids, masked_tokens, masked_pos, False])\n",
        "    \n",
        "  return batch\n",
        "\n",
        "def f(x):\n",
        "  return torch.LongTensor(x)\n",
        "batch = make_data()\n",
        "input_ids, segment_ids, masked_tokens, masked_pos, isnext = zip(*batch)\n",
        "input_ids = f(input_ids)\n",
        "segment_ids = f(segment_ids)\n",
        "masked_tokens = f(masked_tokens)\n",
        "masked_pos = f(masked_pos)\n",
        "isnext = f(isnext)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wCPiYfDb1Gu"
      },
      "source": [
        "class MyDataSet(Data.Dataset):\n",
        "  def __init__(self, input_ids, segment_ids, masked_tokens, masked_pos, isnext):\n",
        "    self.input_ids = input_ids\n",
        "    self.segment_ids = segment_ids\n",
        "    self.masked_tokens = masked_tokens\n",
        "    self.masked_pos = masked_pos\n",
        "    self.isnext = isnext\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.segment_ids[idx], self.masked_tokens[idx], self.masked_pos[idx], self.isnext[idx]\n",
        "\n",
        "loader = Data.DataLoader(MyDataSet(input_ids, segment_ids, masked_tokens, masked_pos, isnext), batch_size, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVtJYSJ5L2hq"
      },
      "source": [
        "def get_attn_pad_mask(seq_q, seq_k):\n",
        "  len_q = seq_q.shape[1]\n",
        "  mask = seq_k.data.eq(0).unsqueeze(1)\n",
        "  return mask.expand(-1, len_q, -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnIvfAgUL4_j",
        "outputId": "b5b69aff-a3e9-4e1e-8f34-faa0dcc1da3e"
      },
      "source": [
        "tmp = torch.tensor([0, 1, 0]).unsqueeze(0)\n",
        "get_attn_pad_mask(tmp, tmp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ True, False,  True],\n",
              "         [ True, False,  True],\n",
              "         [ True, False,  True]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9ffMYMLNYKL"
      },
      "source": [
        "def gelu(x):\n",
        "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4rvvtlZNbfW"
      },
      "source": [
        "class Embedding(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Embedding, self).__init__()\n",
        "    self.pos_embedding = nn.Embedding(maxlen, d_model)\n",
        "    self.tok_embedding = nn.Embedding(vocab_size, d_model)\n",
        "    self.seg_embedding = nn.Embedding(n_segments, d_model)\n",
        "    self.norm = nn.LayerNorm(d_model)\n",
        "  def forward(self, x, seg):\n",
        "    seq_len = x.shape[1]\n",
        "    pos = torch.arange(seq_len, dtype = torch.long)\n",
        "    pos = pos.unsqueeze(0).expand_as(x)\n",
        "    emb = self.pos_embedding(pos) + self.tok_embedding(x) + self.seg_embedding(seg)\n",
        "    return self.norm(emb)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGFiAO3jZpEc",
        "outputId": "9787da1b-7352-4529-a878-7ae4565bc6e0"
      },
      "source": [
        "test = Embedding()\n",
        "emb = test(input_ids, segment_ids)\n",
        "emb.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 30, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZBP44Saj0CN"
      },
      "source": [
        "class ScaledDotProductAttention(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(ScaledDotProductAttention, self).__init__()\n",
        "  def forward(self, q, k, v, mask):\n",
        "    scores = torch.matmul(q, k.transpose(-1, -2)) / np.sqrt(d_k)\n",
        "    scores.masked_fill_(mask, -1e9)\n",
        "    attn = nn.Softmax(dim=-1)(scores)\n",
        "    context = torch.matmul(attn, v)\n",
        "    return context, attn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8k3b_dVH8b0",
        "outputId": "543f5946-cab6-4137-abd3-b2629d36711f"
      },
      "source": [
        "test = ScaledDotProductAttention()\n",
        "tmp = torch.randn(2, n_heads, 4, 5)\n",
        "sq = sk = torch.tensor([[1, 1, 0, 0],[2 , 3, 0, 0]])\n",
        "\n",
        "mask = get_attn_pad_mask(sq, sk)\n",
        "m = mask.unsqueeze(1).repeat(1, n_heads, 1, 1)\n",
        "c, a = test(tmp, tmp, tmp, m)\n",
        "\n",
        "print(c.shape, a.shape)\n",
        "print(a[0, 0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 12, 4, 5]) torch.Size([2, 12, 4, 4])\n",
            "tensor([[0.5690, 0.4310, 0.0000, 0.0000],\n",
            "        [0.4828, 0.5172, 0.0000, 0.0000],\n",
            "        [0.5154, 0.4846, 0.0000, 0.0000],\n",
            "        [0.4784, 0.5216, 0.0000, 0.0000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TJNw1fmsMw1"
      },
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "    self.wq = nn.Linear(d_model, n_heads * d_k)\n",
        "    self.wk = nn.Linear(d_model, n_heads * d_k)\n",
        "    self.wv = nn.Linear(d_model, n_heads * d_v)\n",
        "    self.dense = nn.Linear(n_heads * d_v, d_model)\n",
        "  def forward(self, qx, kx, vx, mask):\n",
        "    # 不能直接用全局变量batch_size,有的batch可能不满足\n",
        "    bs = qx.shape[0]\n",
        "    # 第一维代表seq_len\n",
        "    q = self.wq(qx).view(bs, -1, n_heads, d_k).transpose(1, 2)\n",
        "    k = self.wk(kx).view(bs, -1, n_heads, d_k).transpose(1, 2)\n",
        "    v = self.wv(vx).view(bs, -1, n_heads, d_v).transpose(1, 2)\n",
        "    mask = mask.unsqueeze(1).repeat(1, n_heads, 1, 1)\n",
        "    # 注意scaleddotproduct是module类，而不是函数\n",
        "    context, _ = ScaledDotProductAttention()(q, k, v, mask)\n",
        "    context = context.transpose(1, 2).contiguous().view(bs, -1, n_heads * d_v)\n",
        "    output = self.dense(context)\n",
        "    return nn.LayerNorm(d_model)(output + qx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvQVUC9NY52I",
        "outputId": "d76b26d3-33c6-46c3-dfd9-e1bb19bdae17"
      },
      "source": [
        "# 2是sq,sk的batch_size, 4是sq,sk的序列长度\n",
        "# 这里测试的tmp是没有n_heads维度的\n",
        "tmp = torch.rand(2, 4, d_model)\n",
        "sq = sk = torch.tensor([[1, 1, 0, 0],[2 , 3, 0, 0]])\n",
        "mask = get_attn_pad_mask(sq, sk)\n",
        "test = MultiHeadAttention()\n",
        "ot = test(tmp, tmp, tmp, mask)\n",
        "print(ot.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 4, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uvwpZabZbd-"
      },
      "source": [
        "class FeedForward(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FeedForward, self).__init__()\n",
        "    self.dense1 = nn.Linear(d_model, d_ff)\n",
        "    self.dense2 = nn.Linear(d_ff, d_model)\n",
        "  def forward(self, x):\n",
        "    return self.dense2(gelu(self.dense1(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhDBFWHTatkr",
        "outputId": "8cbceab3-d371-41e5-c36e-d38850c4270b"
      },
      "source": [
        "test = FeedForward()\n",
        "test(ot).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxCnmXaPj__Y"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(EncoderLayer, self).__init__()\n",
        "    self.attention = MultiHeadAttention()\n",
        "    self.feedforward = FeedForward()\n",
        "  def forward(self, inputs, mask):\n",
        "    outputs = self.attention(inputs, inputs, inputs, mask)\n",
        "    outputs = self.feedforward(outputs)\n",
        "    return outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_E5aT-IkD0I",
        "outputId": "9c0d6d7c-cc33-40bf-d804-476fdd4ef0a8"
      },
      "source": [
        "test = EncoderLayer()\n",
        "tmp = torch.rand(2, 4, d_model)\n",
        "mask = get_attn_pad_mask(sq, sk)\n",
        "test(tmp, mask).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 4, 768])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5GikC9Zljla",
        "outputId": "127b501e-3297-405d-a1a4-fbd26fe19629"
      },
      "source": [
        "ln0 = nn.Linear(3, 2)\n",
        "print(ln0.weight.shape)\n",
        "ln = nn.Linear(2, 3)\n",
        "# ln.weight = ln0.weight\n",
        "ln(torch.tensor([1.0, 1.0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.8619,  0.5594, -0.4929], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbTZ-BYNobBe"
      },
      "source": [
        "class BERT(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(BERT, self).__init__()\n",
        "    self.embedding = Embedding()\n",
        "    self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n",
        "    # 句子匹配最后处理层\n",
        "    self.matchds = nn.Sequential(nn.Linear(d_model, d_model),\n",
        "                  nn.Dropout(0.5),\n",
        "                  nn.Tanh())\n",
        "    self.matchclf = nn.Linear(d_model, 2)\n",
        "    # 完形填空最后处理层\n",
        "    self.predds = nn.Linear(d_model, d_model)\n",
        "    wt = self.embedding.tok_embedding.weight\n",
        "    self.predclf = nn.Linear(d_model, vocab_size, bias=False)\n",
        "    self.predclf.weight = wt\n",
        "    self.active = gelu\n",
        "\n",
        "  def forward(self, input_ids, segment_ids, masked_pos):\n",
        "    outputs = self.embedding(input_ids, segment_ids)\n",
        "    mask = get_attn_pad_mask(input_ids, input_ids)\n",
        "    for layer in self.layers:\n",
        "      outputs = layer(outputs, mask)\n",
        "    # 句子匹配任务\n",
        "    h_pooled = self.matchds(outputs[:, 0])\n",
        "    matchclfs = self.matchclf(h_pooled)\n",
        "    # 完型填空任务\n",
        "    masked_pos = masked_pos[:, :, None].expand(-1, -1, d_model)\n",
        "    h_masked = torch.gather(outputs, 1, masked_pos)\n",
        "    h_masked = self.active(self.predds(h_masked))\n",
        "    predclfs = self.predclf(h_masked)\n",
        "    return predclfs, matchclfs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARvFqVzgp0mU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd770da4-130b-42f4-be40-8ce02ce13c71"
      },
      "source": [
        "model = BERT()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adadelta(model.parameters(), lr=0.001)\n",
        "for epoch in range(180):\n",
        "  for input_ids, segment_ids, masked_tokens, masked_pos, isNext in loader:\n",
        "    logits_lm, logits_clsf = model(input_ids, segment_ids, masked_pos)\n",
        "    loss_lm = criterion(logits_lm.view(-1, vocab_size), masked_tokens.view(-1)) # for masked LM\n",
        "    loss_lm = (loss_lm.float()).mean()\n",
        "    loss_clsf = criterion(logits_clsf, isNext) # for sentence classification\n",
        "    loss = loss_lm + loss_clsf\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "      print('Epoch:', '%04d' % (epoch + 1), 'loss =', '{:.6f}'.format(loss))\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0010 loss = 0.868357\n",
            "Epoch: 0020 loss = 0.786383\n",
            "Epoch: 0030 loss = 0.733968\n",
            "Epoch: 0040 loss = 0.728615\n",
            "Epoch: 0050 loss = 0.744979\n",
            "Epoch: 0060 loss = 0.697057\n",
            "Epoch: 0070 loss = 0.673936\n",
            "Epoch: 0080 loss = 0.664784\n",
            "Epoch: 0090 loss = 0.633446\n",
            "Epoch: 0100 loss = 0.646477\n",
            "Epoch: 0110 loss = 0.600737\n",
            "Epoch: 0120 loss = 0.524431\n",
            "Epoch: 0130 loss = 0.460449\n",
            "Epoch: 0140 loss = 0.512675\n",
            "Epoch: 0150 loss = 0.446397\n",
            "Epoch: 0160 loss = 0.476192\n",
            "Epoch: 0170 loss = 0.421251\n",
            "Epoch: 0180 loss = 0.287784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUdjXTTlr_ny",
        "outputId": "5c3f6e64-72f3-414c-db41-1de1dbf34d63"
      },
      "source": [
        "for idx in range(5):\n",
        "  print('---------', idx)\n",
        "  input_ids, segment_ids, masked_tokens, masked_pos, isNext = batch[idx]\n",
        "  print([idx2word[w] for w in input_ids if idx2word[w] != '[PAD]'])\n",
        "\n",
        "  logits_lm, logits_clsf = model(torch.LongTensor([input_ids]), \\\n",
        "                  torch.LongTensor([segment_ids]), torch.LongTensor([masked_pos]))\n",
        "  logits_lm = logits_lm.data.max(2)[1][0].data.numpy()\n",
        "  print('masked pos :', masked_pos)\n",
        "  print('masked tokens list : ',[idx2word[pos] for pos in masked_tokens if pos != 0])\n",
        "  print('predict masked tokens list : ',[idx2word[pos] for pos in logits_lm if pos != 0])\n",
        "\n",
        "  logits_clsf = logits_clsf.data.max(1)[1].data.numpy()[0]\n",
        "  print('isNext : ', True if isNext else False)\n",
        "  print('predict isNext : ',True if logits_clsf else False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------- 0\n",
            "['[CLS]', 'nice', 'meet', 'team', 'too', 'how', 'are', 'you', 'today', '[SEP]', 'great', 'my', 'baseball', 'team', 'won', 'the', 'competition', '[SEP]']\n",
            "masked pos : [13, 3, 0, 0, 0]\n",
            "masked tokens list :  ['team', 'you']\n",
            "predict masked tokens list :  ['team', 'you']\n",
            "isNext :  True\n",
            "predict isNext :  True\n",
            "--------- 1\n",
            "['[CLS]', 'hello', '[MASK]', 'my', 'name', 'is', 'juliet', 'nice', 'to', 'meet', 'you', '[SEP]', 'hello', 'romeo', 'my', 'name', 'is', 'juliet', '[MASK]', 'to', 'meet', 'you', '[SEP]']\n",
            "masked pos : [13, 2, 18, 0, 0]\n",
            "masked tokens list :  ['romeo', 'romeo', 'nice']\n",
            "predict masked tokens list :  ['romeo', 'romeo', 'nice']\n",
            "isNext :  False\n",
            "predict isNext :  False\n",
            "--------- 2\n",
            "['[CLS]', 'hello', 'romeo', 'my', 'name', '[MASK]', 'juliet', 'nice', 'to', 'meet', 'you', '[SEP]', 'nice', '[MASK]', 'you', 'too', 'how', 'are', 'you', 'today', '[SEP]']\n",
            "masked pos : [1, 13, 5, 0, 0]\n",
            "masked tokens list :  ['hello', 'meet', 'is']\n",
            "predict masked tokens list :  ['hello', 'meet', 'is']\n",
            "isNext :  True\n",
            "predict isNext :  False\n",
            "--------- 3\n",
            "['[CLS]', 'hello', 'how', 'are', 'you', '[MASK]', 'am', '[MASK]', '[SEP]', 'hello', 'romeo', 'my', 'name', 'is', 'juliet', 'nice', 'to', 'meet', 'you', '[SEP]']\n",
            "masked pos : [18, 7, 5, 0, 0]\n",
            "masked tokens list :  ['you', 'romeo', 'i']\n",
            "predict masked tokens list :  ['you', 'romeo', 'i']\n",
            "isNext :  False\n",
            "predict isNext :  False\n",
            "--------- 4\n",
            "['[CLS]', 'oh', 'congratulations', 'juliet', '[SEP]', 'thank', 'you', 'romeo', '[SEP]']\n",
            "masked pos : [1, 0, 0, 0, 0]\n",
            "masked tokens list :  ['oh']\n",
            "predict masked tokens list :  ['oh']\n",
            "isNext :  True\n",
            "predict isNext :  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVM4WQ3VsInv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}